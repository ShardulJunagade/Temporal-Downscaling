{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d839f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 12. Syndicate of Civil Engineers (SynOCE): Climate Data Science\n",
    "\n",
    "# **Stakeholders:**  \n",
    "# Prathmesh Maharshi (+91 70159 21044), SynocE IITGN  \n",
    "\n",
    "# ---\n",
    "\n",
    "# ## Team Size: 1 or 2\n",
    "\n",
    "# ### Temporal Downscaling Challenge\n",
    "\n",
    "# Climate and hydrological models often produce coarse-resolution outputs (e.g., monthly or yearly data), which are insufficient for applications requiring high-frequency insights, such as flood forecasting, urban water management, and climate adaptation. This challenge invites participants to develop machine learning (ML) or statistical approaches to **downscale coarse-resolution time series data (e.g., monthly rainfall, temperature, or river discharge)** into **high-resolution daily or hourly data** for enhanced civil and environmental engineering decision-making.\n",
    "\n",
    "# #### Objectives\n",
    "# - Develop a method to predict **finer-resolution (daily/hourly) values** from coarse data.\n",
    "# - Evaluate model performance using statistical and physical consistency metrics.\n",
    "# - Apply the downscaled data to real-world applications such as hydrology, disaster management, and climate modelling.\n",
    "\n",
    "# #### Challenge Details\n",
    "\n",
    "# **A. Provided Dataset**\n",
    "# 1. **Coarse-resolution time series data** (e.g., monthly climate or hydrological variables).\n",
    "# 2. **Observed high-resolution (daily/hourly) data** for validation.\n",
    "# 3. Additional environmental parameters such as elevation, humidity, and wind speed (optional).\n",
    "\n",
    "# **B. Expected Solution Approaches**  \n",
    "# Participants may use one or a combination of the following techniques:\n",
    "\n",
    "# 1. **Traditional Statistical Downscaling**\n",
    "#    - Linear interpolation methods\n",
    "#    - Multiple regression models\n",
    "#    - Wavelet transform for multi-scale decomposition\n",
    "\n",
    "# 2. **Machine Learning-Based Downscaling**\n",
    "#    - Random Forest, XGBoost, or Support Vector Regression (SVR)\n",
    "#    - Recurrent Neural Networks (RNNs) such as LSTM/GRU\n",
    "#    - Gaussian Processes for Probabilistic Predictions\n",
    "\n",
    "# 3. **Deep Learning Super-Resolution for Time Series**\n",
    "#    - Temporal Convolutional Networks (TCN)\n",
    "#    - Transformer-based models for time series forecasting\n",
    "#    - Generative Adversarial Networks (GANs) for realistic high-frequency data\n",
    "\n",
    "# **Evaluation Criteria**\n",
    "\n",
    "# | Metric                        | Description                                                                 |\n",
    "# |-------------------------------|-----------------------------------------------------------------------------|\n",
    "# | Nash-Sutcliffe Efficiency (NSE) | Measures predictive power (closer to 1 is better)                          |\n",
    "# | Root Mean Square Error (RMSE)  | Lower values indicate better accuracy                                      |\n",
    "# | Mean Absolute Error (MAE)      | Measures absolute prediction error                                         |\n",
    "# | Physical Consistency           | Does the predicted time series maintain realistic hydrological/climatic behaviour? |\n",
    "\n",
    "# **Bonus Considerations**\n",
    "# - Interpretability: Clear explanation of model behaviour.\n",
    "# - Generalizability: Ability to apply the model to different datasets.\n",
    "# - Computational Efficiency: Feasibility of real-time deployment.\n",
    "\n",
    "# **Free Resources for Participants**\n",
    "# 3. **Useful Libraries**\n",
    "#    - **Scikit-learn**: Machine learning algorithms.\n",
    "#    - **TensorFlow/PyTorch**: Deep learning frameworks.\n",
    "#    - **Statsmodels**: Statistical modelling in Python.\n",
    "#    - **xarray & pandas**: Time series data handling.\n",
    "\n",
    "# ### Expected Outcomes\n",
    "# - A trained model capable of generating daily/hourly time series from monthly data.\n",
    "# - Performance analysis of different downscaling techniques.\n",
    "# - Real-world application in hydrology, climate modelling, and disaster preparedness.\n",
    "\n",
    "# This challenge aims to encourage innovative applications of ML/AI in civil and environmental engineering while equipping participants with valuable skills in spatiotemporal data analysis. Best of luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dafea",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set all seed\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f78e3e5",
   "metadata": {},
   "source": [
    "### Defining Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2682b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, x_col, y_col, title, xlabel, ylabel, figsize=(15,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(df[x_col], df[y_col])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_nse(observed, predicted):\n",
    "    \"\"\"Calculate Nash-Sutcliffe Efficiency (NSE)\"\"\"\n",
    "    numerator = np.sum((observed - predicted) ** 2)\n",
    "    denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    return nse\n",
    "\n",
    "def calculate_rmse(observed, predicted):\n",
    "    \"\"\"Calculate Root Mean Square Error (RMSE)\"\"\"\n",
    "    rmse = np.sqrt(np.mean((observed - predicted) ** 2))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def calculate_mae(observed, predicted):\n",
    "    \"\"\"Calculate Mean Absolute Error (MAE)\"\"\"\n",
    "    mae = np.mean(np.abs(observed - predicted))\n",
    "    return mae\n",
    "\n",
    "def calculate_physical_consistency(observed, predicted):\n",
    "    \"\"\"Check if predicted values are realistic (e.g., non-negative)\"\"\"\n",
    "    consistency = np.all(predicted >= 0)\n",
    "    return consistency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f5e475",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd5166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training data: 87672\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "train_df['valid_time'] = pd.to_datetime(train_df['valid_time'])\n",
    "print(\"Number of rows in training data:\", len(train_df))\n",
    "\n",
    "# val_df = pd.read_csv(os.path.join(data_dir, 'val_data.csv'))\n",
    "# val_df['valid_time'] = pd.to_datetime(val_df['valid_time'])\n",
    "# print(\"Number of rows in validation data:\", len(val_df))\n",
    "\n",
    "# test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "# test_df['valid_time'] = pd.to_datetime(test_df['valid_time'])\n",
    "# print(\"Number of rows in test data:\", len(test_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
