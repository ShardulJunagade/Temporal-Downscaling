{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15701005",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de00d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch.nn as nn\n",
    "\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# set all seed\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93103995",
   "metadata": {},
   "source": [
    "### Defining Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccd2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_data(df, x_col, y_col, title, xlabel, ylabel, figsize=(15,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(df[x_col], df[y_col])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_nse(observed, predicted):\n",
    "    \"\"\"Calculate Nash-Sutcliffe Efficiency (NSE)\"\"\"\n",
    "    numerator = np.sum((observed - predicted) ** 2)\n",
    "    denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    return nse\n",
    "\n",
    "def calculate_rmse(observed, predicted):\n",
    "    \"\"\"Calculate Root Mean Square Error (RMSE)\"\"\"\n",
    "    rmse = np.sqrt(np.mean((observed - predicted) ** 2))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def calculate_mae(observed, predicted):\n",
    "    \"\"\"Calculate Mean Absolute Error (MAE)\"\"\"\n",
    "    mae = np.mean(np.abs(observed - predicted))\n",
    "    return mae\n",
    "\n",
    "def calculate_physical_consistency(observed, predicted):\n",
    "    \"\"\"Check if predicted values are realistic (e.g., non-negative)\"\"\"\n",
    "    consistency = np.all(predicted >= 0)\n",
    "    return consistency\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calc_metrics(observed, predicted):\n",
    "    rmse = calculate_rmse(observed, predicted)\n",
    "    mae = calculate_mae(observed, predicted)\n",
    "    nse = calculate_nse(observed, predicted)\n",
    "    physical_consistency = calculate_physical_consistency(observed, predicted)\n",
    "    print(f\"RMSE = {rmse:.2f}, MAE = {mae:.2f}, NSE = {nse:.2f}, Physical Consistency = {physical_consistency}\")\n",
    "    return rmse, mae, nse, physical_consistency\n",
    "\n",
    "\n",
    "def plot_ground_truth_vs_prediction(df, y_pred, title_hourly, title_daily, ylabel, figsize=(15, 5)):\n",
    "    \"\"\"Plot ground truth vs predictions for hourly and daily data.\"\"\"\n",
    "    # Plot hourly predictions\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(df['valid_time'], df['tp'], label='Ground Truth', color='blue')\n",
    "    plt.plot(df['valid_time'], y_pred[:, 0], label='Predicted Hourly', color='orange')\n",
    "    plt.title(title_hourly)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot daily predictions\n",
    "    daily_pred_df = pd.merge(df[['valid_time']], pd.DataFrame(y_pred, columns=target), left_index=True, right_index=True)\n",
    "    daily_pred_df = daily_pred_df[daily_pred_df['valid_time'].dt.hour == 0]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(df[df['valid_time'].dt.hour == 0]['valid_time'], df[df['valid_time'].dt.hour == 0]['tp'], label='Ground Truth', color='blue')\n",
    "    plt.plot(daily_pred_df['valid_time'], daily_pred_df['tp'], label='Predicted Daily', color='orange')\n",
    "    plt.title(title_daily)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0aeaa8",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a85160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cycle_features(df):\n",
    "    \"\"\"Add cyclic features for month and year to the dataframe.\"\"\"\n",
    "    df['valid_time'] = pd.to_datetime(df['valid_time'])\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['valid_time'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['valid_time'].dt.month / 12)\n",
    "    df['year_sin'] = np.sin(2 * np.pi * df['valid_time'].dt.year / 12)\n",
    "    df['year_cos'] = np.cos(2 * np.pi * df['valid_time'].dt.year / 12)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4728186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (87672, 25)\n",
      "Shape of validation data: (17520, 25)\n",
      "Shape of test data: (17544, 25)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "train_df = add_cycle_features(train_df)\n",
    "train_df.drop(columns=['second', 'minute'], inplace=True)\n",
    "train_df['valid_time'] = pd.to_datetime(train_df['valid_time'])\n",
    "print(\"Shape of training data:\", train_df.shape)\n",
    "\n",
    "val_df = pd.read_csv(os.path.join(data_dir, 'val_data.csv'))\n",
    "val_df = add_cycle_features(val_df)\n",
    "val_df.drop(columns=['second', 'minute'], inplace=True)\n",
    "val_df['valid_time'] = pd.to_datetime(val_df['valid_time'])\n",
    "print(\"Shape of validation data:\", val_df.shape)\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "test_df = add_cycle_features(test_df)\n",
    "test_df.drop(columns=['second', 'minute'], inplace=True)\n",
    "test_df['valid_time'] = pd.to_datetime(test_df['valid_time'])\n",
    "print(\"Shape of test data:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc82bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>yearly_mean</th>\n",
       "      <th>yearly_max</th>\n",
       "      <th>yearly_min</th>\n",
       "      <th>yearly_std</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_var</th>\n",
       "      <th>daily_mean</th>\n",
       "      <th>daily_max</th>\n",
       "      <th>daily_min</th>\n",
       "      <th>daily_std</th>\n",
       "      <th>daily_var</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>9.706095e-10</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.801785e-09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>9.706095e-10</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.801785e-09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>9.706095e-10</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.801785e-09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>9.706095e-10</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.801785e-09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>9.706095e-10</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.801785e-09</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           valid_time        tp  year  month  day  hour  yearly_mean  \\\n",
       "0 2011-01-01 00:00:00  0.000166  2011      1    1     0      0.00028   \n",
       "1 2011-01-01 01:00:00  0.000103  2011      1    1     1      0.00028   \n",
       "2 2011-01-01 02:00:00  0.000083  2011      1    1     2      0.00028   \n",
       "3 2011-01-01 03:00:00  0.000078  2011      1    1     3      0.00028   \n",
       "4 2011-01-01 04:00:00  0.000095  2011      1    1     4      0.00028   \n",
       "\n",
       "   yearly_max  yearly_min  yearly_std  ...   monthly_var  daily_mean  \\\n",
       "0    0.003323         0.0    0.000407  ...  9.706095e-10    0.000069   \n",
       "1    0.003323         0.0    0.000407  ...  9.706095e-10    0.000069   \n",
       "2    0.003323         0.0    0.000407  ...  9.706095e-10    0.000069   \n",
       "3    0.003323         0.0    0.000407  ...  9.706095e-10    0.000069   \n",
       "4    0.003323         0.0    0.000407  ...  9.706095e-10    0.000069   \n",
       "\n",
       "   daily_max  daily_min  daily_std     daily_var  month_sin  month_cos  \\\n",
       "0   0.000166   0.000026   0.000042  1.801785e-09        0.5   0.866025   \n",
       "1   0.000166   0.000026   0.000042  1.801785e-09        0.5   0.866025   \n",
       "2   0.000166   0.000026   0.000042  1.801785e-09        0.5   0.866025   \n",
       "3   0.000166   0.000026   0.000042  1.801785e-09        0.5   0.866025   \n",
       "4   0.000166   0.000026   0.000042  1.801785e-09        0.5   0.866025   \n",
       "\n",
       "   year_sin  year_cos  \n",
       "0      -0.5 -0.866025  \n",
       "1      -0.5 -0.866025  \n",
       "2      -0.5 -0.866025  \n",
       "3      -0.5 -0.866025  \n",
       "4      -0.5 -0.866025  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year', 'month', 'day', 'hour',\n",
    "            'yearly_mean', 'yearly_max', 'yearly_min', 'yearly_std', 'yearly_var',\n",
    "            'monthly_mean', 'monthly_max', 'monthly_min', 'monthly_std', 'monthly_var',\n",
    "            'month_sin', 'month_cos', 'year_sin', 'year_cos']\n",
    "target = ['tp']\n",
    "\n",
    "\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    for feature in [f for f in features + target if f not in ['month_sin', 'month_cos', 'year_sin', 'year_cos', 'year', 'month', 'day', 'hour']]:\n",
    "        df[feature] = np.log(df[feature] + 1e-4)  # Avoid log(0) by adding a small constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0fe4e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0abbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, features, target, seq_length=24):\n",
    "        self.X = df[features].values.astype('float32')\n",
    "        self.y = df[target].values.astype('float32')\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx:idx + self.seq_length]\n",
    "        y = self.y[idx + self.seq_length - 1]\n",
    "        return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "seq_length = 24*2\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(train_df, features, target, seq_length)\n",
    "val_dataset = TimeSeriesDataset(val_df, features, target, seq_length)\n",
    "test_dataset = TimeSeriesDataset(test_df, features, target, seq_length)\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=24, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ecceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state (batch_size, num_layers, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # x shape: (batch_size, seq_length, input_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply fully connected layer to the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a90135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 18\n",
      "Hidden size: 64\n",
      "Number of layers: 2\n",
      "Output size: 1\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (adjust based on your data)\n",
    "input_size = len(features)  # Number of features\n",
    "hidden_size = 64  # Number of LSTM units\n",
    "num_layers = 2\n",
    "output_size = len(target)  # Number of target variables\n",
    "learning_rate = 0.001\n",
    "\n",
    "save_path = './models/'\n",
    "import shutil\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee2a695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(18, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3692491",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_checkpoint=True):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for batch_idx, (X, y) in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item() * X.size(0)\n",
    "        epoch_train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (X, y) in tqdm(enumerate(val_loader), total=len(val_loader), desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(model.state_dict(), save_path + 'best_model.pth')\n",
    "            print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "        \n",
    "        if save_checkpoint:\n",
    "            torch.save(model.state_dict(), save_path + f'model_epoch_{epoch+1}.pth')\n",
    "\n",
    "    return model, best_model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item() * X.size(0)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    all_preds = np.exp(all_preds) - 1e-4  # Inverse transformation\n",
    "    all_targets = np.exp(all_targets) - 1e-4  # Inverse transformation\n",
    "    return all_preds, all_targets, test_loss\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "# Train the model\n",
    "model, best_model, train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "# Evaluate the model on the test set\n",
    "y_pred, y_true, test_loss = evaluate_model(model, test_loader)\n",
    "# Calculate performance metrics\n",
    "rmse, mae, nse, physical_consistency = calc_metrics(y_true, y_pred)\n",
    "# Plot ground truth vs predictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_df['valid_time'], test_df['tp'], label='Ground Truth', color='blue')\n",
    "plt.plot(test_df['valid_time'], y_pred[:, 0], label='Predicted', color='orange')\n",
    "plt.title('Ground Truth vs Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
